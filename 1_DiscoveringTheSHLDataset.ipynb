{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "1_DiscoveringTheSHLDataset.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "LwoonJfAEomp",
        "iLuyV4Vo_JYj"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3uq0-bSUnVx6"
      },
      "source": [
        "# 0. Setting-up the Development Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lab steps\n",
        "\n",
        "\n",
        "*   Integrate Github to your Colab: facilitate data uploading process\n",
        "*   Download code and data from github to your google drive\n",
        "*   Visualize the data"
      ],
      "metadata": {
        "id": "jNZIejTL3cg3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LbbywV1YIS0Y"
      },
      "source": [
        "## Resources\n",
        "\n",
        "* An introduction to the features provided by colab [here](https://colab.research.google.com/notebooks/intro.ipynb) (In French);\n",
        "* Another introduction to the features provided by colab [here](https://colab.research.google.com/notebooks/basic_features_overview.ipynb);\n",
        "* Mise à niveau in Python, Numpy, Matplotlib can be found [here](https://colab.research.google.com/github/cs231n/cs231n.github.io/blob/master/python-colab.ipynb) (From Stanford's cs231n course);\n",
        "* An introductory colab to Tensorflow 2 can be found [here](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/tutorials/quickstart/beginner.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Integration between Drive-Colab-Github\n",
        "\n",
        "The following contents are based on the following tutorials: [this tutorial](https://towardsdatascience.com/google-drive-google-colab-github-dont-just-read-do-it-5554d5824228); [this tutorial](https://towardsdatascience.com/colaboratory-drive-github-the-workflow-made-simpler-bde89fba8a39). "
      ],
      "metadata": {
        "id": "6TZP8o2vtmB4"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QLqXIJmpH4W4"
      },
      "source": [
        "\n",
        "### The workflow\n",
        "The workflow we will be using during the labs is a simple four-step process:\n",
        "0. First, you will need to create a fresh new Google Drive dedicated solely for this Lab;\n",
        "1. After connecting to the Colab runtime, you need to mount Google Drive and update your space using Github;\n",
        "2. You work with the notebooks and needed files (your modules, libraries, etc.)as on editor;\n",
        "3. (optional) You save your work, by synchronizing your Drive with Github using the operational notebook.\n",
        "\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://user-images.githubusercontent.com/8298445/104195015-6086cb80-5422-11eb-8cba-60ab7478c5ac.png\" width=\"300px\" title=\"https://towardsdatascience.com/colaboratory-drive-github-the-workflow-made-simpler-bde89fba8a39\"/>\n",
        "</p>\n",
        "<p align=\"center\">\n",
        "Figure: From <a src=\"https://towardsdatascience.com/colaboratory-drive-github-the-workflow-made-simpler-bde89fba8a39\">this tutorial</a>.\n",
        "</p>\n",
        "\n",
        "\n",
        "Before we discuss in detail, let’s take a look at each roles of those components (Google Drive, Google Colab, GitHub) and their interactions (Based on [this tutorial](https://towardsdatascience.com/google-drive-google-colab-github-dont-just-read-do-it-5554d5824228)).\n",
        "\n",
        "* **Google Colab:**  is used as shell to run bash commands and git commands.\n",
        "* **Google Drive:** When we use Google Colab, our work is stored temporary in a virtual machine around 8 to 12 hours. Google Drive gives a possibility to store your training in cloud storage hosting. Google Drive provides free 15 GB storage and allows easy integration with Google Colab. We will use it as a location to store the clone GitHub repo that we work on permanently.\n",
        "* **GitHub:** A code hosting platform for version control and collaboration which hosts the repository containing this notebook. In addition to this notebook, the repository contains also other useful code.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQq3IECH5TUG"
      },
      "source": [
        "### Connecting, mounting and updating"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LC1npyAH5U2Z"
      },
      "source": [
        "from google.colab import drive\n",
        "from os.path import join\n",
        "\n",
        "ROOT = '/content/drive'     # default for the drive\n",
        "PROJ = 'MyDrive/ml-iot'       # path to your project on Drive\n",
        "\n",
        "drive._mount(ROOT)           # we mount the drive at /content/drive\n",
        "\n",
        "PROJECT_PATH = join(ROOT, PROJ)\n",
        "!mkdir \"{PROJECT_PATH}\"    # in case we haven't created it already\n",
        "%cd \"{PROJECT_PATH}\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-ETr4T16Cz2"
      },
      "source": [
        "GIT_REPOSITORY = \"2022-ml-iot-lab-2\"\n",
        "GIT_PATH = \"https://github.com/institut-galilee/\"+ GIT_REPOSITORY + \".git\"\n",
        "!git clone \"{GIT_PATH}\"\n",
        "!cd \"{GIT_REPOSITORY}\"\n",
        "# !rsync -aP --exclude=\"{GIT_REPOSITORY}\"/data/ \"{GIT_REPOSITORY}\"/generated/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQZEPU-pfQw4"
      },
      "source": [
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIYELnLY5y02"
      },
      "source": [
        "The above snippet mounts the Google Drive at /content/drive and creates our project's directory. It then pulls all the files from Github and copies them over to that directory. Finally, it collects everything that belongs to the Drive directory and copies it over to our local runtime.\n",
        "\n",
        "A nice thing about this solution is that it won’t crash if executed multiple times. Whenever executed, it will only update what is new and that’s it. Also, with rsync we have the option to exclude some of the content, which may take too long to copy (...data?)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LwoonJfAEomp"
      },
      "source": [
        "### [Optional] Save changes to GitHub\n",
        "\n",
        "(Optional, only in the case you work on your own fork of the repository!)\n",
        "\n",
        "In order to save your changes, please perform the following commands. These allow you to put your modifications in your fork (code repository)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "upGBlFa9EnVn"
      },
      "source": [
        "# !git add .\n",
        "# !git commit -m \"Put here a message that describes your modifications. e.g. answering question 3\"\n",
        "# !git config --global user.email \"your github email\"\n",
        "# !git config --global user.name \"your first and last name\"\n",
        "# !git push origin master"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Discovering the SHL Dataset"
      ],
      "metadata": {
        "id": "DpyIHZRwtwQa"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iLuyV4Vo_JYj"
      },
      "source": [
        "## Goals/Outline\n",
        "\n",
        "In these first series of lab, we will take a look at the Sussex-Huawei Locomotion (SHL) dataset. We will also build our first Keras model and train it in order to recognize human activities (run, walk, bike, etc.) from sensory data like accelerometer, gyroscope, magnetometer, etc.\n",
        "\n",
        "1. We will first work on a subset of the SHL dataset containing only examples from one of the four body locations (**Torso**, Hips, Hand, and Bag) and three of the fifteen modalities (**accelerometer, gyroscope, magnetometer**, gravitation, ambient pressure, etc.);\n",
        "\n",
        "2. We will build a sample (échantillon de données) which will be used to train our activity recognition models.\n",
        "\n",
        "4. We will take a look at the signals, visualize them, apply some preprocessings on them, and extract some valuable features from them;\n",
        "\n",
        "1. We will see the dimensions and structure of the dataset that we use to feed the keras models with;\n",
        "\n",
        "3. We will explore both raw signal and feature-based activity recognition models;\n",
        "\n",
        "4. After adding other modalities, we will explore various sensor fusion schemes, i.e. channel, modality, and grouped fusion."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DeZfXMhxG8rd"
      },
      "source": [
        "## Download a subset of the dataset\n",
        "\n",
        "In this part, we will launch two scripts, `get_data.sh` and `extract_data.sh` which will download a subset of the SHL dataset and extract it to the right folder, respectively.\n",
        "If you want to work, as a personal side project, on the original dataset (really heavy), you can check out the commented lines inside `get_data.sh`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dWH4_fcD8LqN"
      },
      "source": [
        "# check where are we located in the filesystem tree\n",
        "!pwd\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpFbp0Szaxd7"
      },
      "source": [
        "# if needed, go inside the cloned repository (be aware of the difference between %cd and !cd.)\n",
        "%cd \"{GIT_REPOSITORY}\"\n",
        "!pwd\n",
        "!ls"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeZlucsfIBlh"
      },
      "source": [
        "# give execution permissions to the two scripts\n",
        "!chmod +x get_data.sh\n",
        "!chmod +x extract_data.sh"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JrQIRMkOISQr"
      },
      "source": [
        "# launch the commands, the downloading may take a while !\n",
        "!./get_data.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DyGnSpxGJ5we"
      },
      "source": [
        "# extract the downloaded zip files using the following command. This also may take a while !\n",
        "!./extract_data.sh"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xjJY12LqFMTv"
      },
      "source": [
        "## Structure of the code repository\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "In the left side, you can see the file system button which allows you to display the contents of the current folder. This structure should be the same as that found in the GitHub repository.\n",
        "\n",
        "```\n",
        "├── data/            # where the initial zipped data will be stored\n",
        "├── generated/       # generated from sample after basic transformations (ready for ML algorithms) \n",
        "     ├── sample/     # subset of data to use in your experiments\n",
        "          ├── train/\n",
        "          └── validation/\n",
        "     ├── tmp/        # where downloaded zipped data will be extracted. This is where data is read from\n",
        "     └── 0.1/        # used to store data in a memory-convinient manner (not to be changed)\n",
        "├── dataset.py       # Python code used to load data\n",
        "├── config.py        # provide needed configurations: paths ... (not to be changed)\n",
        "├── sample.py        # contains the code to extract samples from the data \n",
        "├── get_data.sh      # shell script to download data \n",
        "└── extract_data.sh\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oG4hra2LL3WB"
      },
      "source": [
        "## Structure of the Raw Dataset\n",
        "\n",
        "We will explore here the structure of the SHL dataset as it is provided by the team responsible of collecting and maintaining it.\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://user-images.githubusercontent.com/8298445/104208754-27a22300-5431-11eb-8a5c-d3093fdf3de4.png\" width=\"300px\"/>\n",
        "</p>\n",
        "\n",
        "```\n",
        "├── generated/\n",
        "    └── sample\n",
        "        ├── train\n",
        "            ├── Torso/\n",
        "                ├── Acc_x.txt\n",
        "                ├── Acc_y.txt\n",
        "                ├── Acc_z.txt\n",
        "                ├── Gyr_x.txt\n",
        "                ...\n",
        "                └── Labels.txt\n",
        "            ├── Hand             # Not included in the subset\n",
        "            ├── Hips             # Not included in the subset\n",
        "            └── Bag              # Not included in the subset\n",
        "        └── validation\n",
        "```\n",
        "\n",
        "To see how the first 10 rows of e.g. `Acc_x.txt` look like, execute the following command.\n",
        "Each row contains 500 data points measured by an accelerometer (the x axis exactly) while the user performs one of the eight given activities. These 500 data points are successive in time and correspond to 5 seconds of the performed activity."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "poHsdLb_LqSQ"
      },
      "source": [
        "!head -10 ./generated/tmp/sample/train/Torso/Acc_x.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OH11IKQXVByp"
      },
      "source": [
        "## Exploring and visualizing the sensory signals\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "We will use Plotly in order to allow exploring the sensory signals in an interactive manner."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### What is Plotly\n",
        "\n",
        "Plotly allows one to create interactive charts and maps with APIs in Python, R, and JavaScript. It's intuitive, highly customisable and from version 4, it integrates nicely with Pandas DataFrames in Python with the [Plotly Express](https://plotly.com/python/plotly-express/) module which was included in Plotly version 4, from being its own module.\n",
        "\n",
        "### Plotly\n",
        "Basic [installation of Plotly](https://plotly.com/python/getting-started/#installation)\n",
        "```bash\n",
        "pip install plotly\n",
        "```\n",
        "This enables Plotly usage in the Python environment. It won't automatically allow you to render Plotly figures in notebooks with `fig.show()`, but it should be possible in notebooks to render them as the following:"
      ],
      "metadata": {
        "id": "8nA3-vYHuebD"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PjUY9vXm_bAn"
      },
      "source": [
        "!pip install plotly"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEPwJXoHV2SK"
      },
      "source": [
        "from IPython.display import HTML\n",
        "import plotly.express as px\n",
        "import pandas as pd\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "df = pd.read_csv('./generated/sample/train/Torso/Gyr_x.txt', sep=' ')\n",
        "\n",
        "fig = go.Figure()\n",
        "for i in range(10):\n",
        "    fig.add_trace(\n",
        "        go.Scatter(\n",
        "            x=[j+(500*i) for j in range(500)],\n",
        "            y=df.iloc[i, :],\n",
        "            mode=\"lines\",\n",
        "            line=go.scatter.Line(color=\"blue\"),\n",
        "            showlegend=False)\n",
        "    )\n",
        "HTML(fig.to_html())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh35Z40bTKxJ"
      },
      "source": [
        "## Loading the dataset\n",
        "\n",
        "Now that we have built a sample and stored it in the drive, this is what we will use to train our activity recognition models.\n",
        "Before that, we need to put the data into a convinient and memory-efficient data structure. The additional value of the backend implementation (which uses OS-base memory mapping) of this data structure will appear when you will work on the entire dataset.\n",
        "In the following, we will just check a high-level overview of the data structure."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The data structure that will be used resemble to the that depicted in the figure below. It has three axis: (0) the elements; (1) time; and (2) the channels.\n",
        "\n",
        "<p align=\"center\">\n",
        "<img src=\"https://user-images.githubusercontent.com/8298445/105118442-b583ab00-5ace-11eb-989b-ac1eba8cb26d.png\" height=\"300px\"/>\n",
        "</p>\n",
        "\n",
        "For these labs, we provide you with a python class, `DataReader`, which loads the data in this format. Use it to load an manipulate the data.\n",
        "\n",
        "In order to see how to manipulate tensors in TensorFlow, plase check out [this](https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/tensor.ipynb) introductory colab."
      ],
      "metadata": {
        "id": "jqRcGnTGuxP0"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Nyf5rsDx7t9"
      },
      "source": [
        "from dataset import DataReader\n",
        "import sample\n",
        "\n",
        "# get the size of the sample\n",
        "sample_idx = sample.load_index(\"./generated/sample/sample_idx.pickle\")\n",
        "sample_size = sample.size_of_index(sample_idx)\n",
        "print(sample_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# when run for the first time, this may take a while!\n",
        "train = DataReader(what='train', train_frames=sample_size)\n",
        "valid = DataReader(what='validation')"
      ],
      "metadata": {
        "id": "QN0ABMTU920H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7QdXMZkiTtop"
      },
      "source": [
        "**TODO**\n",
        "Check out the shape of the returned objects and try to visualize its contents using the provided methods inside the class `Dataset` (`dataset.py`)."
      ]
    }
  ]
}